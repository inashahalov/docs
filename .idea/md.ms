Система для анализа структуры PostgreSQL и генерации DDL для MS SQL.

Цель: Добавить возможность работы с новой системой управления базами данных (в моем случае — PostgreSQL), не нарушая существующую логику приложения, за счёт заранее предусмотренной гибкой архитектуры. Создать расширяемую систему для анализа структуры БД, чтения метаданных и генерации DDL, поддерживающую разные СУБД через единый интерфейс.

Абстрактный класс BaseDatabase (database/base.py) Это контракт — то, что обязана уметь любая поддерживаемая СУБД.Чтобы любой код, работающий с БД (миграция), мог вызывать db.get_tables() независимо от того, PostgreSQL это или MS SQL

Фабрика factory.py позволяет создавать нужную реализацию по имени СУБД.

Согласование нейминга — любой код, использующий BaseDatabase, знает, что ожидать.

Функция проверки доступа -Реализована в check_read_access() — минимальная проверка: может ли пользователь читать из системных таблиц или хотя бы одну таблицу.?

Система анализа структуры PostgreSQL и генерации DDL для MS SQL
Инструмент для безопасного и расширяемого анализа метаданных PostgreSQL и автоматической генерации совместимых DDL-скриптов для Microsoft SQL Server. Поддерживает правильную последовательность миграции (справочники → факты) и интеграцию с Apache Airflow.

Структура проекта
migration-data/
├── database/                 # Абстракции и реализации СУБД
│   ├── __init__.py
│   ├── inspector.py          # Абстрактный класс DatabaseInspector
│   ├── registry.py           # Фабрика get_inspector()
│   ├── type_mapping.py       # Преобразование типов PG → MS SQL
│   └── dialects/
│       ├── __init__.py
│       └── postgres.py       # Реализация для PostgreSQL
├── ddl/
│   ├── __init__.py
│   └── generator.py          # Генерация DDL для MS SQL
├── utils/
│   └── dag_utils.py          # Топологическая сортировка таблиц
├── dags/                     # DAG-файлы для Airflow
│   └── pg_to_mssql_ddl.py
├── docker-compose.yaml       # Запуск Airflow + PostgreSQL
├── example.py                # Локальный запуск (анализ + вывод в консоль)
└── save_file.py              # Локальный запуск с сохранением DDL в файл
Быстрый старт
1. Подготовка окружения
2. Запуск тестовой БД
3. Настройка кредов
4. Запуск анализа
Запуск с Airflow
1. Подготовка
2. Запуск Airflow + PostgreSQL
3. Подготовка DAG
4. Настройка Connections
5. Запуск миграции
